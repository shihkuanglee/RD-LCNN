{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c444adf-7ca7-451c-a623-9c12261e0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, time, shutil\n",
    "from     pathlib import Path\n",
    "from collections import Counter\n",
    "from    datetime import datetime, timedelta\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--device\",         type=str,   default='cuda',  help=\"Specify 'cpu' or 'cuda'\")\n",
    "parser.add_argument(\"--cuda_vd\",        type=str,   default='None',  help=\"CUDA_VISIBLE_DEVICES\")\n",
    "parser.add_argument(\"--seed\",           type=int,   default=999,     help=\"Seed value\")\n",
    "parser.add_argument(\"--epochs\",         type=int,   default=400,     help=\"The number of epochs\")\n",
    "parser.add_argument(\"--esep\",           type=int,   default=200,     help=\"The number of early stop epoch\")\n",
    "parser.add_argument(\"--ep_eval\",        type=int,   default=50,      help=\"The number of epoch to start evaluation\")\n",
    "parser.add_argument(\"--bsize\",          type=int,   default=10,      help=\"Batch size\")\n",
    "parser.add_argument(\"--WRSns\",          type=int,   default=3000,    help=\"Specify number of batch to active WeightedRandomSampler\")\n",
    "parser.add_argument(\"--num_workers\",    type=int,   default=0,       help=\"The number of workers for DataLoader\")\n",
    "parser.add_argument(\"--lr\",             type=float, default=-1,      help=\"Learning rate, -1 means 0.1, -2 means 0.01\")\n",
    "parser.add_argument(\"--lr_lmbda\",       type=float, default=-1,      help=\"The value of lr_lmbda for MultiplicativeLR, -1 means 0.1\")\n",
    "parser.add_argument(\"--lr_step_wait\",   type=int,   default=50,      help=\"learning rate step wait epochs\")\n",
    "parser.add_argument(\"--opt\",            type=str,   default='sgd',   help=\"optimizer name\")\n",
    "parser.add_argument(\"--cp\",             type=float, default='inf',   help=\"To clips gradient norm\")\n",
    "parser.add_argument(\"--momentum\",       type=float, default=0,       help=\"momentum value\")\n",
    "parser.add_argument(\"--weight_decay\",   type=float, default=0,       help=\"The value of weight_decay for optimizer\")\n",
    "parser.add_argument(\"--scheduler\",      type=str,   default='None',  help=\"scheduler name, None or MultiplicativeLR\")\n",
    "parser.add_argument(\"--dmode_train\",    type=str,   default='train', help=\"dmode for  train Dataset\")\n",
    "parser.add_argument(\"--dmode___dev\",    type=str,   default='eval',  help=\"dmode for    dev Dataset\")\n",
    "parser.add_argument(\"--dmode__eval\",    type=str,   default='eval',  help=\"dmode for   eval Dataset\")\n",
    "# parser.add_argument(\"--path_data\",      type=str,   required=True,   help=\"Specify path of ASVspoof2019 directory\")\n",
    "# parser.add_argument(\"--task\",           type=str,   default='PA',    help=\"Specify task of ASVspoof2019, LA or PA\")\n",
    "# parser.add_argument(\"--conifg_section\", type=str,   required=True,   help=\"Specify config section for different features\")\n",
    "parser.add_argument(\"--info\",           type=str,                    help=\"additional message\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.cuda_vd = '0'\n",
    "args.dmode_train = 'fixed'\n",
    "args.dmode___dev = 'fixed'\n",
    "args.dmode__eval = 'fixed'\n",
    "args.path_data = '../ASVspoof2019'\n",
    "args.task = 'PA'\n",
    "args.conifg_section = 'QTAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5b62b-9a16-474f-9ade-5310a7c24aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import   configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "dim_f          = config.getint(args.conifg_section, 'dim_f')\n",
    "dim_t          = config.getint(args.conifg_section, 'dim_t')\n",
    "feature_folder = config.get(   args.conifg_section, 'feature_folder')\n",
    "file_extension = config.get(   args.conifg_section, 'file_extension')\n",
    "\n",
    "from dataset import get_list_dict_task_online as get_list_dict\n",
    "list_path_train, dict_cm_train, \\\n",
    "list_path___dev, dict_cm___dev, asv_data__dev, \\\n",
    "list_path__eval, dict_cm__eval, asv_data_eval= \\\n",
    "get_list_dict(Path(args.path_data), args.task, feature_folder, file_extension)\n",
    "from dataset import Dataset_online as Data_set\n",
    "dataset_dev = Data_set(list_path___dev, dict_cm___dev, config, args.conifg_section, args.dmode___dev)\n",
    "dataset_eva = Data_set(list_path__eval, dict_cm__eval, config, args.conifg_section, args.dmode__eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ed4af-9fda-45fd-bcfe-f9db3492a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import numpy    as np\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(args.device)\n",
    "random.seed(      int(args.seed))\n",
    "np.random.seed(   int(args.seed))\n",
    "torch.manual_seed(int(args.seed))\n",
    "cudnn.deterministic = True\n",
    "\n",
    "class__counts___dev = Counter(dict_cm___dev.values())\n",
    "counts__class___dev = [class__counts___dev[False], class__counts___dev[True]]\n",
    "class_weights___dev = [1 - (x / class__counts___dev.total()) for x in counts__class___dev]\n",
    "Dloader_dev = DataLoader(dataset_dev, batch_size=args.bsize, shuffle=False, num_workers=args.num_workers, collate_fn=None)\n",
    "nl_criterion___dev = nn.CrossEntropyLoss(torch.tensor(class_weights___dev, dtype=torch.float32)).to(device)\n",
    "\n",
    "nl_criterion = nn.CrossEntropyLoss().to(device)\n",
    "Dloader_eva = DataLoader(dataset_eva, batch_size=args.bsize, shuffle=False, num_workers=args.num_workers, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ceee7-6cf7-458f-b72e-94d04a25a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import T45_LCNN as Model\n",
    "model = Model(data_shape=[dim_f, dim_t], LDO_p1=0.75, LDO_p2=0.00).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda70f7-12b8-4bd4-b110-799cfe0fa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(args.bsize, 1, dim_f, dim_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6c287-abd5-483a-96a5-21cd0749b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = -1\n",
    "save_folder_name = 'exp__QTAC'\n",
    "save_folder_path = Path(os.getcwd()).home() / save_folder_name\n",
    "MODL_PATH = save_folder_path / 'modl' / f'modl__ep_{ep:03d}.pt'\n",
    "model.load_state_dict(torch.load(MODL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d29700-41d8-40b5-8937-d2310814dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_eval_infer import spf_det_eval\n",
    "from em.em_2019 import get_eer, get_tDCF\n",
    "\n",
    "time_start = time.time()\n",
    "loss___dev_avg, name___dev, scrs___dev, cmky___dev = spf_det_eval(model, device, Dloader_dev, nl_criterion___dev)\n",
    "time_dev = time.time() - time_start\n",
    "\n",
    "bona__cm___dev = scrs___dev[cmky___dev == 'bonafide']\n",
    "spoof_cm___dev = scrs___dev[cmky___dev == 'spoof']\n",
    "min_tDCF___dev = get_tDCF(asv_data__dev, bona__cm___dev, spoof_cm___dev)\n",
    "eer___cm___dev = get_eer(bona__cm___dev, spoof_cm___dev)[0] * 100\n",
    "\n",
    "if min_tDCF___dev == 0: str_first_tdcf = f'dev tDCF EER:{            \" 0\":<6s}'\n",
    "else:                   str_first_tdcf = f'dev tDCF EER:{min_tDCF___dev:>7.4f}'\n",
    "\n",
    "if eer___cm___dev == 0: str_secnd      = f'{str_first_tdcf}{            \" 0\":<6s}'\n",
    "else:                   str_secnd      = f'{str_first_tdcf}{eer___cm___dev:>7.4f}'\n",
    "\n",
    "print(f'{str_secnd}  time-dev:{str(timedelta(seconds=int(time_dev))):>8s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2f161-39e0-41cb-9ee7-240f760c512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAPADF = 'PA'\n",
    "ASV_2021_root = Path(os.getcwd()).parent / 'ASVspoof2021'\n",
    "ASV_2021__dir = f'ASVspoof2021_{LAPADF}_eval'\n",
    "ASV_2021_filelist_path = ASV_2021_root / ASV_2021__dir / f'ASVspoof2021.{LAPADF}.cm.eval.trl.txt'\n",
    "ASV_2021_filelist = list(np.genfromtxt(ASV_2021_filelist_path, dtype=str))\n",
    "data_path_predict = ASV_2021_root / ASV_2021__dir / feature_folder\n",
    "list_path_predict = [data_path_predict / f'{name}.{file_extension}' for name in ASV_2021_filelist]\n",
    "print(list_path_predict[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_eval_infer import spf_det_infer\n",
    "\n",
    "dataset_2021_eval = Data_set(list_path_predict, 'infer', config, args.conifg_section, args.dmode__eval)\n",
    "Dloader_2021_eval = DataLoader(dataset_2021_eval, batch_size=args.bsize, shuffle=False, num_workers=args.num_workers, collate_fn=None)\n",
    "\n",
    "time_start = time.time()\n",
    "name_predict, scrs_predict = spf_det_infer(model, device, Dloader_2021_eval)\n",
    "time_2021_eval = time.time() - time_start\n",
    "print(f' time-2021-{LAPADF}-eval:{str(timedelta(seconds=int(time_2021_eval))):>8s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ASV_2021_filelist))\n",
    "print(len(name_predict))\n",
    "print(len(scrs_predict))\n",
    "assert len(name_predict) == len(scrs_predict)\n",
    "\n",
    "print(max(scrs_predict))\n",
    "print(min(scrs_predict))\n",
    "np.save(f'ASVspoof2021-{LAPADF}-scrs-eval-{args.conifg_section}-name', name_predict)\n",
    "np.save(f'ASVspoof2021-{LAPADF}-scrs-eval-{args.conifg_section}', scrs_predict)\n",
    "\n",
    "with open(f'ASVspoof2021-{LAPADF}-scrs-eval-{args.conifg_section}.txt', 'w') as f:\n",
    "    for i in range(len(name_predict)):\n",
    "        _ = f.write(f'{name_predict[i]} {scrs_predict[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ca2b5-f309-422e-a57b-cd0f4030d023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
